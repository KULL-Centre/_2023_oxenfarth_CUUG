{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715323fb-9631-4e8e-9c5c-ca18bfbdf8db",
   "metadata": {},
   "source": [
    "This notebook might not be usable \"out of the box\" and is mainly meant to give an idea how the data was calculated from the NMR bundles and the MD ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46ab12-5d54-46d0-b119-8b73cf5477f1",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95716aff-00f7-4a23-a22a-28f5165682e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import barnaba as bb\n",
    "from barnaba import definitions\n",
    "import subprocess as sub\n",
    "import regex as re\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7113f6a-7d54-40f4-9002-38b97d6e94b6",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9753c57-e533-49cd-813e-c7ac62d108e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load( inp ):\n",
    "    pin = open( inp, \"rb\" )\n",
    "    return pkl.load( pin )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08764d9b-92ad-4bcd-aac9-073bb2471a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save( outfile, results ):\n",
    "    with open( outfile + \".pkl\", \"wb\" ) as fp:\n",
    "        pkl.dump( results, fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ca716c-f984-4fa7-8aeb-8bf94e27e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS TO CALCULATE NOE DISTANCES ###\n",
    "\n",
    "# helper functions, subsititute strings. This is because the name of hydrogens is a mess\n",
    "# alt = {\"H2'\":\"1H2'\",\"H5''\":\"2H5'\",\"H5'\":\"1H5'\",\"HO2'\":\"2HO'\",\"H5\\\"\":\"2H5'\",\"H5'2\":\"2H5'\",\"H5'1\":\"1H5'\"}\n",
    "alt = {\"H2'\":\"H2'1\",\"H5''\":\"H5'2\",\"H5'\":\"H5'1\",\"HO2'\":\"HO'2\"}\n",
    "\n",
    "def sub(ss):\n",
    "    at = \"H\" + ss.split(\"H\")[1]\n",
    "    if(at in alt):\n",
    "        at = alt[at]\n",
    "    return ss.split(\"H\")[0] + at\n",
    "\n",
    "# read experimental datafile and returns a list of labels and experimental values\n",
    "def read_exp(f_exp):\n",
    "    labels = []\n",
    "    vals = []\n",
    "    with open(f_exp) as fh:\n",
    "        for line in fh:\n",
    "            if(\"#\" not in line):\n",
    "                r1 = line.split()[0].split(\"-\")[0]\n",
    "                print(r1)\n",
    "                r2 = line.split()[0].split(\"-\")[1]\n",
    "                print(r2)\n",
    "                v1 = np.sort([r1,r2])\n",
    "                print(v1)\n",
    "                qq = v1[0] +\"/\"+ v1[1]\n",
    "                \n",
    "                if(qq in labels):\n",
    "                    print(\"# DUPLICATE. Skipping data..\"),\n",
    "                    print(qq,vals[labels.index(qq)], line),\n",
    "                else:\n",
    "                    vals.append([float(line.split()[1]),float(line.split()[2])])\n",
    "                    labels.append(qq)\n",
    "    return labels,vals\n",
    "\n",
    "# get labels from df column (Assignment) \n",
    "def get_labels(df, col):\n",
    "    labels = []\n",
    "    for asm in df.iloc[:,col]:\n",
    "        r1 = asm.split()[0].split(\"-\")[0]\n",
    "        r2 = asm.split()[0].split(\"-\")[1]\n",
    "        v1 = np.sort([r1,r2])\n",
    "        qq = v1[0] +\"/\"+ v1[1]\n",
    "        labels.append(qq)\n",
    "    return labels\n",
    "\n",
    "# find indeces in topology corresponding to labels in experimental datafile\n",
    "def get_idxs(labels,top):\n",
    "\n",
    "    atoms = []\n",
    "    for atom in top.atoms:\n",
    "        aa = str(atom).split(\"-\")[1]\n",
    "        if(aa in alt): aa = alt[aa]\n",
    "        atoms.append(\"%s%s\" % (str(atom).split(\"-\")[0],aa))\n",
    "    pairs = []\n",
    "    for el in labels:\n",
    "        ss  = el.split(\"/\")\n",
    "        at1 = sub(ss[0])\n",
    "        at2 = sub(ss[1])\n",
    "        if(at1 in atoms and at2 in atoms):\n",
    "            pairs.append([atoms.index(at1),atoms.index(at2)])\n",
    "        else:\n",
    "            print(\"# Warning: Either %s or %s are missing\" % (at1,at2))\n",
    "            return 0\n",
    "    if len(pairs) != len(labels):\n",
    "        print(\"# Found only %d pairs out of %d\" % (len(pairs),len(labels)))\n",
    "    return np.array(pairs)\n",
    "\n",
    "def group_by_heading( some_source ):\n",
    "    buffer= []\n",
    "    for line in some_source:\n",
    "        if line.startswith( \" ASSI\" ):\n",
    "            if buffer: yield buffer\n",
    "            buffer= [ line.strip().strip(')') ]\n",
    "        else:\n",
    "            buffer.append( line.strip().strip(')') )\n",
    "    yield buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07e59b-529f-4500-848a-ae1dba147873",
   "metadata": {},
   "source": [
    "# From NMR bundles\n",
    "\n",
    "Back-calculate experimental observables from ```Bundle_E.pdb```, ```Bundle_F.pdb``` and ```1RNG.pdb```.\n",
    "\n",
    "Since some of the forward models need certain PDB formats we have to reformat the PDB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b3b351-5bdf-4369-9670-3c99cb050f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMR bundle directory:\n",
    "bundles_dir = 'nmrbundle_data/'\n",
    "\n",
    "# Bundle identifiers:\n",
    "bundles = ['E', 'F', '1RNG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba62988-94a3-4879-b798-875e374748c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RDCs\n",
    "\n",
    "We use the pf1-phage prediction method implemented in *PALES** to back-calculate RDCs. In order to do that we use the script ```calc_rdc_bundles.py``` which submits each frame to *PALES*, predicts the alignment tensor and calculates RDCs, parses the output and saves the D values in a Pickle file.\n",
    "\n",
    "The actual command line to run *PALES is*: ```pales-linux -inD exp_data/exp_rdc_pales.tab -pdb {pdb_tmp} -outD {outd_tmp} -pf1 -H -wv 0.05```\n",
    "\n",
    "\n",
    "*Zweckstetter, M. NMR: Prediction of molecular alignment from structure using the PALES software. Nat. Protoc. 3, 679–690 (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c8cf2a86-a00f-4577-bd2c-0ae26245d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc_exp_input = pd.read_csv('exp_data/exp_rdc_pales.tab', names=['RESID_I', 'RESNAME_I', 'ATOMNAME_I', 'RESID_J', 'RESNAME_J',\n",
    "       'ATOMNAME_J', 'D', 'DD', 'W'], delim_whitespace=True, skiprows=5)\n",
    "# all residues:\n",
    "rdc_exp_labels_all = [f\"{row[1]['RESNAME_I'][0]}{row[1]['RESID_I']}_{row[1]['ATOMNAME_I']}-{row[1]['ATOMNAME_J']}\" for row in rdc_exp_input.iterrows()]\n",
    "# loop residues:\n",
    "rdc_exp_labels_loop = [f\"{row[1]['RESNAME_I'][0]}{row[1]['RESID_I']}_{row[1]['ATOMNAME_I']}-{row[1]['ATOMNAME_J']}\" for row in rdc_exp_input.iterrows() if row[1]['RESID_I'] in [5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "709146fb-5480-4f63-a0fe-159c93c3dbae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *--------------------------------------------------------------------* \n",
      " |               PALES                      (C) M. Zweckstetter 2000  | \n",
      " *--------------------------------------------------------------------*\n",
      "\n",
      " \n",
      "\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//rdcs/frame_0.pdb, 383 Atoms, Residues 2 to 13.\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/FINAL_DATA_18112022/cuugrdc_all308.tab, 30 Couplings, Residues 1 to 13.\n",
      "REMARK Orientation 2196 of 2196\n",
      "REMARK Memory Allocation Status. Reused: 656 In Use: 2887796\n",
      "\n",
      "\n",
      " *--------------------------------------------------------------------* \n",
      " |               PALES                      (C) M. Zweckstetter 2000  | \n",
      " *--------------------------------------------------------------------*\n",
      "\n",
      " \n",
      "\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//rdcs/frame_1.pdb, 383 Atoms, Residues 2 to 13.\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/FINAL_DATA_18112022/cuugrdc_all308.tab, 30 Couplings, Residues 1 to 13.\n",
      "REMARK Orientation 2196 of 2196\n",
      "REMARK Memory Allocation Status. Reused: 656 In Use: 2887796\n",
      "\n",
      "\n",
      " *--------------------------------------------------------------------* \n",
      " |               PALES                      (C) M. Zweckstetter 2000  | \n",
      " *--------------------------------------------------------------------*\n",
      "\n",
      " \n",
      "\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//rdcs/frame_2.pdb, 383 Atoms, Residues 2 to 13.\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/FINAL_DATA_18112022/cuugrdc_all308.tab, 30 Couplings, Residues 1 to 13.\n",
      "REMARK Orientation 2196 of 2196\n",
      "REMARK Memory Allocation Status. Reused: 656 In Use: 2887796\n",
      "\n",
      "\n",
      " *--------------------------------------------------------------------* \n",
      " |               PALES                      (C) M. Zweckstetter 2000  | \n",
      " *--------------------------------------------------------------------*\n",
      "\n",
      " \n",
      "\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//rdcs/frame_3.pdb, 383 Atoms, Residues 2 to 13.\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/FINAL_DATA_18112022/cuugrdc_all308.tab, 30 Couplings, Residues 1 to 13.\n",
      "REMARK Orientation 2196 of 2196\n",
      "REMARK Memory Allocation Status. Reused: 656 In Use: 2887796\n",
      "\n",
      "\n",
      " *--------------------------------------------------------------------* \n",
      " |               PALES                      (C) M. Zweckstetter 2000  | \n",
      " *--------------------------------------------------------------------*\n",
      "\n",
      " \n",
      "\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//rdcs/frame_4.pdb, 383 Atoms, Residues 2 to 13.\n",
      "/storage1/kummerer/TETRALOOPS/CUUG/exp_data/FINAL_DATA_18112022/cuugrdc_all308.tab, 30 Couplings, Residues 1 to 13.\n",
      "REMARK Orientation 2196 of 2196\n",
      "REMARK Memory Allocation Status. Reused: 656 In Use: 2887796\n"
     ]
    }
   ],
   "source": [
    "for bundle in bundles:\n",
    "    process = sub.Popen(f'python {bundles_dir}/calc_rdc_traj.py {bundle}', shell=True, stdin=sub.PIPE, stdout=sub.PIPE, universal_newlines=True)\n",
    "    process.wait() # needed to run one process at a time (because of using temporary files etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4b52f-3a01-4442-b66c-a89ff433c5b8",
   "metadata": {},
   "source": [
    "Parse the output and write BME readable files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5816136-1cea-4d7d-b873-4a419bbb2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bundle in bundles:\n",
    "    df = load(f'{bundles_dir}/nmrbundle_{bundle}_d_df_pf1.pkl')\n",
    "    for i in rdc_exp_labels_all: # missing residues in 1RNG\n",
    "        if i not in df.columns:\n",
    "            df[i] = np.full((len(df)), np.nan)\n",
    "    \n",
    "    # All res:\n",
    "    df[rdc_exp_labels_all].to_csv(f'{bundles_dir}/nmrbundle_{bundle}_rdc_all_bme.dat', header=False, sep='\\t', na_rep=np.nan)\n",
    "    # Loop only:\n",
    "    df[rdc_exp_labels_loop].to_csv(f'{bundles_dir}/nmrbundle_{bundle}_rdc_loop_bme.dat', header=False, sep='\\t', na_rep=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2627721-6d7f-444b-847d-35d3c439927d",
   "metadata": {},
   "source": [
    "The predicted RDCs need to be scaled to the experimental values before comparing them. To reduce the effect of over-fitting we scale the RDCs based on all measurements and since we treat NMR structures as a bundle of structures rather than an ensemble we do the scaling for all individual structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99d8c040-7ffa-42fd-9fd6-1ebcaaad2adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42217735 -0.47304937 -0.42535987 -0.38887352 -0.42488561 -0.42047199\n",
      " -0.42816358 -0.42314775 -0.4282601  -0.44315126 -0.41305291 -0.42628107\n",
      " -0.49120921 -0.42238565 -0.49735445 -0.45195944 -0.38918149 -0.45317832\n",
      " -0.42410985 -0.42566778]\n",
      "[-0.3559229  -0.37141832 -0.4071307  -0.42057445 -0.4817862  -0.4574938\n",
      " -0.36979183 -0.34962068 -0.36812801 -0.40707106 -0.37666958 -0.38420109\n",
      " -0.33849285 -0.40938766 -0.38990872 -0.3528908  -0.36597962 -0.36588416\n",
      " -0.38999744 -0.40099118]\n",
      "[-0.49517812 -0.5017432  -0.47475832 -0.50159652 -0.51723057 -0.51994268\n",
      " -0.47711362 -0.48615831 -0.45209726 -0.54786246 -0.46050511 -0.50893858\n",
      " -0.45273783 -0.44680576 -0.50977555 -0.47868166 -0.45465672 -0.4379871\n",
      " -0.46705837 -0.4584089 ]\n",
      "[-0.44475955 -0.43542508 -0.42223536 -0.49241141 -0.48400591 -0.45570632\n",
      " -0.47337935 -0.44771636 -0.40395842 -0.4375156  -0.4809261  -0.41498865\n",
      " -0.47143533 -0.48384091 -0.476374   -0.4863376  -0.45259264 -0.41579333\n",
      " -0.46093421 -0.41923211]\n",
      "[-0.42334988 -0.47236752 -0.4231598  -0.46876543 -0.4511017  -0.435756\n",
      " -0.45133744 -0.44184098 -0.44436526 -0.445861   -0.46162688 -0.41073106\n",
      " -0.4548118  -0.4717472  -0.5177012  -0.45968422 -0.45897057 -0.4276837\n",
      " -0.47583879 -0.48335973]\n",
      "[-0.48561933 -0.48279315 -0.43384964 -0.47101778 -0.49751408 -0.49709847\n",
      " -0.46143911 -0.45524194 -0.44622011 -0.50806866 -0.4605698  -0.44791051\n",
      " -0.46820594 -0.49923296 -0.47722252 -0.5295799  -0.43727607 -0.46977147\n",
      " -0.43648584 -0.52042664]\n",
      "[-0.41178452 -0.3101379  -0.24590084 -0.16013561 -0.3704043 ]\n"
     ]
    }
   ],
   "source": [
    "for bundle in bundles:\n",
    "    rdc_bundle = np.loadtxt(f'{bundles_dir}/nmrbundle_{bundle}_rdc_all_bme.dat')\n",
    "    L = np.zeros(len(rdc_bundle))\n",
    "    for i in range(len(L)):\n",
    "        masked = np.ma.array(rdc_bundle[i,1:], mask=np.isnan(rdc_bundle[i,1:])) # mask NaNs (only present in 1RNG due to missing/different residues in the stem)\n",
    "        L[i] = np.sum(np.array(rdc_exp_input['D'])*masked)/np.sum(masked*masked)\n",
    "    # print(L)\n",
    "    np.save(f'{bundles_dir}/nmrbundle_{bundle}_rdc_all_bme_L', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ff0a1-ac3e-4a8e-b90d-0a1e07ae22be",
   "metadata": {},
   "source": [
    "## $^3$J-couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffe8bf-dbbc-4638-9562-417be0252484",
   "metadata": {},
   "source": [
    "We use Barnaba* to calculate the $^3$J scalar couplings 2H5H4, H1H2, H2H3, H3P, C4Pb, 1H5P, 1H5H4, C4Pe, 2H5P and H3H4.\n",
    "\n",
    "Definition: $A cos^2 (\\theta + \\phi) + B cos (\\theta + \\phi) + C$\n",
    "\n",
    "*Bottaro, S. et al. Barnaba: software for analysis of nucleic acid structures and trajectories. Rna 25, 219–231 (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b05d8be-ecce-410b-82b2-930a47333197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H1H2': [9.67, -2.03, 0.0, 0.0, 0.0],\n",
       " 'H2H3': [9.67, -2.03, 0.0, 0.0, 0.0],\n",
       " 'H3H4': [9.67, -2.03, 0.0, 0.0, 0.0],\n",
       " '1H5P': [15.3, -6.1, 1.6, 0.0, -2.094395],\n",
       " '2H5P': [15.3, -6.1, 1.6, 0.0, 2.094395],\n",
       " 'C4Pb': [6.9, -3.4, 0.7, 0.0, 0.0],\n",
       " '1H5H4': [9.7, -1.8, 0.0, 0.0, -2.094395],\n",
       " '2H5H4': [9.7, -1.8, 0.0, 0.0, 0.0],\n",
       " 'H3P': [15.3, -6.1, 1.6, 0.0, 2.094395],\n",
       " 'C4Pe': [6.9, -3.4, 0.7, 0.0, 0.0],\n",
       " 'H1C2/4': [4.7, 2.3, 0.1, 0.0, -1.0471975],\n",
       " 'H1C6/8': [4.5, -0.6, 0.1, 0.0, -1.0471975]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A (Hz), B (Hz), C (Hz), _, phi (rad)\n",
    "bb.definitions.couplings_karplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0d56a9e-913a-4622-99d0-22d3beeef762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_A_gmx.pdb \n",
      "/lindorffgrp-isilon/kummerer/software/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_B_gmx.pdb \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_C_gmx.pdb \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_D_gmx.pdb \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_E_gmx.pdb \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_F_gmx.pdb \n",
      "# Loading /storage1/kummerer/TETRALOOPS/CUUG/exp_data/paper_bundles//Bundle_1RNG_gmx.pdb \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(20, 14, 10)\n",
      "(14, 10)\n",
      "Calculated jcouplings for ['1H5H4', 'C4Pe', '1H5P', 'H3P', 'C4Pb', '2H5P', 'H3H4', '2H5H4', 'H2H3', 'H1H2'].\n",
      "(5, 12, 10)\n",
      "(12, 10)\n"
     ]
    }
   ],
   "source": [
    "j3_exp_labels = list(pd.read_csv('exp_data/exp_j3_bme.dat', delim_whitespace=True).index) # ONLY EXTENDED-LOOP RESIDUES!!!\n",
    "j3_exp_couplings = list(set([ i.split('-')[-1] for i in j3_exp_labels ]))\n",
    "\n",
    "barnaba_to_exp = {'H1H2':\"H1',H2'\", 'H2H3':\"H2',H3'\", 'H3H4':\"H3',H4'\",\\\n",
    "                '1H5P':\"H5'i,Pi\", '2H5P':\"H5''i,Pi\",\\\n",
    "                'C4Pb':\"C4'i,Pi\", '1H5H4':\"NA\", '2H5H4':\"NA\", \\\n",
    "                'H3P':\"H3'i,Pi+1\" ,'C4Pe':\"C4'i,Pi+1\", \\\n",
    "                'H1C2/4':\"NA\", 'H1C6/8':\"NA\"}\n",
    "\n",
    "# the shape of couplings is (nframes, nresidues, ncouplings)\n",
    "\n",
    "for bundle in bundles:\n",
    "    traj_file   = f'{bundles_dir}/Bundle_{bundle}_gmx.pdb'\n",
    "    top_file    = f'{bundles_dir}/Bundle_{bundle}_gmx.pdb'\n",
    "\n",
    "    couplings,residues = bb.jcouplings(traj_file, topology=top_file, couplings=j3_exp_couplings)\n",
    "    print( f'Calculated jcouplings for {j3_exp_couplings}.' )\n",
    "    print( couplings.shape )\n",
    "\n",
    "    couplings_avg = np.average( couplings, 0 )\n",
    "    print(couplings_avg.shape)\n",
    "    \n",
    "    j3_calc_ = pd.DataFrame()\n",
    "    for i,ii in enumerate([ i.split('_')[0]+i.split('_')[1] for i in rr ]):\n",
    "        for j,jj in enumerate(j3_exp_couplings):\n",
    "            j3_calc_[f'{ii}-{jj}'] = couplings[:,i,j]\n",
    "\n",
    "    ll = []\n",
    "    for i in j3_exp_labels:\n",
    "        ll.append(j3_calc_[i])\n",
    "    pd.DataFrame(ll).T.to_csv(f'{bundles_dir}/nmrbundle_{bundle}_j3_loop_bme.dat', sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9a591-8741-4c3c-b7ae-51a54d90b22c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCRs\n",
    "\n",
    "We use the script ```calc_ccr.py``` to back-calculate CCRs from pdb files or trajectories\n",
    "Important notes:\n",
    "- The PDB naming has to be in a specific format (check the script if in doubt).\n",
    "- Here, $\\Gamma$-HCP (C4p-P, C3p-P-plus, C4p-P-plus) and $\\Gamma$-HCNCH (C1-CC) are measured at 600 MHz (14.09 T) while $\\Gamma$-HCCH (C1-C2, C3-C4) is measured at 700 MHz (16.44 T) which means that in theory the script has to be executed twice and B0 has to be adjusted accordingly. However, $\\Gamma$-HCCH couplings are not influenced by B0 which is why we can ignore this for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fb333-35de-4741-afd4-ad16055f6693",
   "metadata": {},
   "source": [
    "Load experimental data to get labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc62ec40-be56-4213-b370-463832c57d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccr_exp_labels_loop  = list(pd.read_csv('exp_data/exp_ccr.dat', delim_whitespace=True, usecols=[0]).index)\n",
    "ccr_exp_loop  = np.loadtxt('exp_data/exp_ccr.dat', usecols=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85965632-32c5-4081-add1-028968b5032e",
   "metadata": {},
   "source": [
    "Calculate CCRs from bundles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e35a2c9-5f8d-4ac9-83c9-d1ceaaeceead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the script and change output name etc.\n",
    "for bundle in bundles:\n",
    "    process = sub.Popen(f'python /storage1/kummerer/scripts/calc_ccr.py Bundle_{bundle}_gmx_ccr.pdb', shell=True, stdin=sub.PIPE, stdout=sub.PIPE, universal_newlines=True)\n",
    "    process.wait() # needed to run one process at a time (because of using temporary files etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c21d2-a54f-4947-9ddb-567126026cdd",
   "metadata": {},
   "source": [
    "Parse calculated data and write to BME file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2bad8d3-7936-4b3c-9143-272d49010a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# for bundle in bundles:\n",
    "#     tmp_ccr_600 = pd.read_csv(f'{bundles_dir}/ccr/600MHz/Bundle_{bundle}_gmx_ccr_calc.dat', delim_whitespace=True, index_col=0)\n",
    "#     tmp_ccr_loop_600 = tmp_ccr_600[ccr_exp_labels_loop]\n",
    "    # tmp_ccr_700 = pd.read_csv(f'{bundles_dir}/ccr/700MHz/Bundle_{bundle}_gmx_ccr_calc.dat', delim_whitespace=True, index_col=0)\n",
    "    # Check if all data points are contained in the bundle:\n",
    "    # print(list(tmp_ccr_loop.columns) == ccr_lbl)\n",
    "    # # Combine 700 MHz data for gamma-HCCH (C1-C2, C3-C4) couplings with the rest at 600 MHz:\n",
    "    # for lbl in [ i for i in ccr_exp_labels_loop if i.split(':')[1] in ['C1-C2', 'C3-C4'] ]:\n",
    "    #     tmp_ccr_600[lbl] = tmp_ccr_700[lbl]\n",
    "    # Save as BME readable file:\n",
    "    # tmp_ccr_loop_600.to_csv(f'{bundles_dir}/ccr/Bundle_{bundle}_gmx_ccr_calc_loop_bme.dat', header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2684bbe-08c1-421b-be4a-4163c048f3ad",
   "metadata": {},
   "source": [
    "NOTE: Don't forget about adding nans for missing measurements in 1RNG when compiling a data file for all residues (including stem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194107b4-088c-4a8b-9f77-7236d268c1cd",
   "metadata": {},
   "source": [
    "## NOEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92995e13-9c72-4588-99d0-6715f7e10046",
   "metadata": {},
   "source": [
    "We load NOEs from an ARIA output file after they have been converted to distances (\\AA). For this, we use the NOEs from bundle F because those have been restraint the most by other types of data. Generally, they don't differ significantly between the different bundles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1198ef-44c6-4868-8843-4eaab270263b",
   "metadata": {},
   "source": [
    "Load and parse experimental NOE distance file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08242bc-cdb3-4f7b-8417-dbbd8ce2855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = {1:'G', 2:'G', 3:'C', 4:'A', 5:'G', 6:'C', 7:'U', 8:'U', 9:'G', 10:'C', 11:'U', 12:'G', 13:'C', 14:'C'}\n",
    "\n",
    "df_noe_exp = pd.DataFrame()\n",
    "\n",
    "with open('exp_data/exp_noe.tbl') as f: # use NOEs from bundle F\n",
    "    \n",
    "    for heading_and_lines in group_by_heading( f ):\n",
    "        heading= heading_and_lines[0]\n",
    "        lines= heading_and_lines[1:]\n",
    "        \n",
    "        resid1 = int(re.search('resid (\\d+)', lines[0] ).group(1))\n",
    "        name1 = re.search('name (.+)', lines[0] ).group(1).strip()\n",
    "        resid2 = int(re.search('resid (\\d+)', lines[1] ).group(1))\n",
    "        name2 = re.search('name (.+)', lines[1] ).group(1).strip()\n",
    "        \n",
    "        row = {'Assignment': f'{seq[resid1]}{resid1}{name1}-{seq[resid2]}{resid2}{name2}', 'distance':float(lines[2].split()[0]), 'upper_err':float(lines[2].split()[1]), 'lower_err':float(lines[2].split()[2])}\n",
    "        df_noe_exp = df_noe_exp.append(row, ignore_index=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2761f2-a171-4ce9-81e5-cbe8e138cc68",
   "metadata": {},
   "source": [
    "Make separate dfs for loop NOEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3944fc5e-6dcc-4dc7-a47c-ee5ca35f851e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop NOEs: 76\n"
     ]
    }
   ],
   "source": [
    "residues = ['G1', 'G2', 'C3', 'A4', 'G5', 'C6', 'U7', 'U8', 'G9', 'C10', 'U11', 'G12', 'C13', 'C14']\n",
    "loop = ['G5','C6', 'U7', 'U8', 'G9','C10']\n",
    "\n",
    "a_loop, a_stem, a_both = [], [], []\n",
    "for i,n in df_noe_exp[:].iterrows():\n",
    "    a = n['Assignment'].split('-')\n",
    "    r1 = re.split('(^[A-Z]\\d+)', a[0])[1]\n",
    "    r2 = re.split('(^[A-Z]\\d+)', a[1])[1]\n",
    "    if r1 in loop and r2 in loop:\n",
    "        a_loop.append(n['Assignment'])\n",
    "    # elif r1 in loop or r2 in loop:\n",
    "    #     a_both.append(n['Assignment'])\n",
    "    # else:\n",
    "    #     a_stem.append(n['Assignment'])\n",
    "print(f'Loop NOEs: {len(a_loop)}')\n",
    "# print( f'Loop NOEs: {len(a_loop)}\\nStem NOEs: {len(a_stem)}\\nIntersect: {len(a_both)}' )\n",
    "\n",
    "df_noe_exp_loop = df_noe_exp.loc[df_noe_exp.Assignment.isin(a_loop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962e4e0-fa9f-4e1a-bf75-adcfdceede2d",
   "metadata": {},
   "source": [
    "Calc distances from the bundles (1RNG has to be done separately due to missing/different residues):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c19b747b-6529-4d69-92ed-53cf2cfdde80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n"
     ]
    }
   ],
   "source": [
    "# Calc distances from the bundles (1RNG has to be one separately due to missing/different residues)\n",
    "for bundle in bundles[:-1]: \n",
    "    print(bundle)\n",
    "    traj_ = md.load_pdb(f'nmrbundle_data/Bundle_{bundle}_gmx.pdb')\n",
    "    # labels = get_labels(df_noe_exp, 0) # For all NOEs\n",
    "    labels = get_labels(df_noe_exp_loop, 0)\n",
    "    pairs = get_idxs( labels, traj_.topology )\n",
    "    # calculate distances multiply by 10 to convert to angs\n",
    "    dists = 10.0*md.compute_distances(traj_,pairs)\n",
    "    df_noe = pd.DataFrame(dists)\n",
    "\n",
    "    df_noe.columns = list(df_noe_exp_loop.Assignment)\n",
    "    # Save to BME format:\n",
    "    df_noe[a_loop].to_csv(f'nmrbundle_data/Bundle_{bundle}_dists_loop.dat', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac818d-9b65-40d9-9113-833ec4f788fc",
   "metadata": {},
   "source": [
    "Calc distances from 1RNG -> only do for loop residues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cfc2c55-87ee-4bab-9072-6e8086844ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1RNG\n"
     ]
    }
   ],
   "source": [
    "# Calc distances from 1RNG -> only do for loop residues:\n",
    "# tmp_labels = pd.DataFrame()\n",
    "# tmp_labels[0] = a_loop\n",
    "\n",
    "for bundle in bundles[-1:]: #['A', 'B', 'C']:\n",
    "    traj_ = md.load_pdb(f'nmrbundle_data/Bundle_{bundle}_gmx_rn.pdb')\n",
    "    print(bundle)\n",
    "    labels = get_labels(df_noe_exp_loop, 0)\n",
    "    pairs = get_idxs( labels, traj_.topology )\n",
    "    # calculate distances multiply by 10 to convert to angs\n",
    "    dists = 10.0*md.compute_distances(traj_,pairs)\n",
    "    df_noe = pd.DataFrame(dists)\n",
    "\n",
    "    df_noe.columns = a_loop\n",
    "    # Save to BME format:\n",
    "    df_noe[a_loop].to_csv(f'nmrbundle_data/Bundle_{bundle}_dists_loop.dat', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e0e47-703b-462d-a54e-b52d4c5f0854",
   "metadata": {},
   "source": [
    "Write BME readable file for the experimental loop noes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ad028a-8d3c-494a-a4dd-efe8a873b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noe_exp_loop_tobme = df_noe_exp_loop.copy().drop(columns=['lower_err', 'upper_err'])\n",
    "df_noe_exp_loop_tobme['avg_err'] = ((df_noe_exp_loop['lower_err']+df_noe_exp_loop['upper_err'])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa4bdb7a-a05d-42f4-b5b8-a4710f3257fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'exp_data/exp_noe_loop_bme.dat', 'w') as f:\n",
    "    f.write('# DATA=NOE POWER=6\\n')\n",
    "    df_noe_exp_loop_tobme.to_csv(f, index= False, header = False, sep = '\\t', float_format='%.2f') #df_noe_exp_tobme[df_noe_exp_tobme['Assignment'].isin(a_loop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb4ad1-5dca-42db-9036-c8ef0e60214e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From MD ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194b5a5-b039-496c-af1f-14fff3fb7b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RDCs\n",
    "\n",
    "We use the pf1-phage prediction method implemented in *PALES** to back-calculate RDCs. In order to do that we use the script ```calc_rdc_traj.py``` which submits each frame to *PALES*, predicts the alignment tensor and calculates RDCs, parses the output and saves the D values in a Pickle file.\n",
    "\n",
    "The actual command line to run *PALES is*: ```pales-linux -inD exp_data/exp_rdc_pales.tab -pdb {pdb_tmp} -outD {outd_tmp} -pf1 -H -wv 0.05```\n",
    "\n",
    "\n",
    "*Zweckstetter, M. NMR: Prediction of molecular alignment from structure using the PALES software. Nat. Protoc. 3, 679–690 (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a76585-75ec-437c-be45-71472365aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the script above:\n",
    "ll = []\n",
    "for i in range(0,20):\n",
    "    df = load(f'cuug_{i}/d_df_pf1.pkl') # Change\n",
    "    ll.append(df)\n",
    "ddff = pd.concat(ll)#, ignore_index=True)\n",
    "d_md = ddff.reset_index(drop=True)[list(d_exp_rdc.index)]\n",
    "d_md_loop = d_md[list(d_exp_rdc_loop.index)]\n",
    "# All to BME\n",
    "# d_md.to_csv(f'calc_data/calc_rdc_bme.dat', header=False, sep='\\t')\n",
    "# Loop to BME:\n",
    "# d_md_loop.to_csv(f'calc_data/calc_rdc_loop_bme.dat', header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973562d1-7cd3-4e22-bf98-506abecd0a9b",
   "metadata": {},
   "source": [
    "## $^3$J-couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b6f30-014e-4516-974e-b5d0fac77d97",
   "metadata": {},
   "source": [
    "We use Barnaba* to calculate the $^3$J scalar couplings 2H5H4, H1H2, H2H3, H3P, C4Pb, 1H5P, 1H5H4, C4Pe, 2H5P and H3H4.\n",
    "\n",
    "Definition: $A cos^2 (\\theta + \\phi) + B cos (\\theta + \\phi) + C$\n",
    "\n",
    "*Bottaro, S. et al. Barnaba: software for analysis of nucleic acid structures and trajectories. Rna 25, 219–231 (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376ca9ee-481e-441e-a155-5f0f28afb88a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading concat_traj_nopbc.xtc \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated jcouplings for ['H1H2', '1H5P', '1H5H4', 'C4Pb', '2H5P', 'H2H3', 'H3P', 'H3H4', 'C4Pe', '2H5H4'].\n",
      "(20100, 14, 10)\n",
      "(14, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lindorffgrp-isilon/kummerer/software/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "j3_exp_labels = list(pd.read_csv('exp_data/exp_j3_bme.dat', delim_whitespace=True).index) # ONLY EXTENDED-LOOP RESIDUES!!!\n",
    "j3_exp_couplings = list(set([ i.split('-')[-1] for i in j3_exp_labels ]))\n",
    "\n",
    "barnaba_to_exp = {'H1H2':\"H1',H2'\", 'H2H3':\"H2',H3'\", 'H3H4':\"H3',H4'\",\\\n",
    "                '1H5P':\"H5'i,Pi\", '2H5P':\"H5''i,Pi\",\\\n",
    "                'C4Pb':\"C4'i,Pi\", '1H5H4':\"NA\", '2H5H4':\"NA\", \\\n",
    "                'H3P':\"H3'i,Pi+1\" ,'C4Pe':\"C4'i,Pi+1\", \\\n",
    "                'H1C2/4':\"NA\", 'H1C6/8':\"NA\"}\n",
    "\n",
    "# the shape of couplings is (nframes, nresidues, ncouplings)\n",
    "\n",
    "traj_file   = f'concat_traj_nopbc.xtc'\n",
    "top_file    = f'initial_nopbc_mdtraj.pdb'\n",
    "\n",
    "couplings,residues = bb.jcouplings(traj_file, topology=top_file, couplings=j3_exp_couplings)\n",
    "print( f'Calculated jcouplings for {j3_exp_couplings}.' )\n",
    "print( couplings.shape )\n",
    "\n",
    "couplings_avg = np.average( couplings, 0 )\n",
    "print(couplings_avg.shape)\n",
    "\n",
    "j3_calc_ = pd.DataFrame()\n",
    "for i,ii in enumerate([ i.split('_')[0]+i.split('_')[1] for i in rr ]):\n",
    "    for j,jj in enumerate(j3_exp_couplings):\n",
    "        j3_calc_[f'{ii}-{jj}'] = couplings[:,i,j]\n",
    "\n",
    "ll = []\n",
    "for i in j3_exp_labels:\n",
    "    ll.append(j3_calc_[i])\n",
    "pd.DataFrame(ll).T.to_csv(f'calc_data/calc_j3_bme.dat', sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2af2f-9a5c-404f-8fdb-48ff6f58b326",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCRs\n",
    "\n",
    "We use the script ```calc_ccr.py``` to back-calculate CCRs from pdb files or trajectories\n",
    "Important notes:\n",
    "- The PDB naming has to be in a specific format (check the script if in doubt).\n",
    "- Here, $\\Gamma$-HCP (C4p-P, C3p-P-plus, C4p-P-plus) and $\\Gamma$-HCNCH (C1-CC) are measured at 600 MHz (14.09 T) while $\\Gamma$-HCCH (C1-C2, C3-C4) is measured at 700 MHz (16.44 T) which means that in theory the script has to be executed twice and B0 has to be adjusted accordingly. However, $\\Gamma$-HCCH couplings are not influenced by B0 which is why we can ignore this for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc522618-9d81-4817-8499-f5e64f0e6c27",
   "metadata": {},
   "source": [
    "## NOEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f553119c-2877-477c-8d08-cd1d40be5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20100, 76)\n"
     ]
    }
   ],
   "source": [
    "dfs_noe = {}\n",
    "labels = get_labels(df_noe_exp_loop, 0)\n",
    "\n",
    "traj_file   = f'concat_traj_nopbc.xtc'\n",
    "top_file    = f'initial_nopbc_mdtraj.pdb'\n",
    "\n",
    "traj  = md.load( traj_file, top = top_file ) # load traj\n",
    "pairs = get_idxs( labels, traj.topology )\n",
    "\n",
    "# calculate distances multiply by 10 to convert to angs\n",
    "dists = 10.0*md.compute_distances(traj,pairs)\n",
    "df_noe = pd.DataFrame(dists)\n",
    "\n",
    "df_noe.columns = list(df_noe_exp_loop['Assignment'])\n",
    "print(df_noe.shape)\n",
    "\n",
    "df_noe.to_csv(f'calc_data/calc_dists_loop_bme.dat', sep='\\t', header=False, float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
